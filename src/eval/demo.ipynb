{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Notebook: How to evaluate your predicted scenes\n",
    "\n",
    "In this notebook, we will demonstrate all the steps you need to evaluate and visualize the results of this pipeline. For every scene you need to make sure you have the following:\n",
    "- A predicted scene result in `results/semantic_labels` as `{pairing}_{scene}_{masks}.pickle`\n",
    "- A GT Point Cloud / mesh of the Scene to project colors and predicted semantics back to the original format in `data/{scene}` as `{scene}_vh_clean_2.ply`\n",
    "- A GT Text file indicating the correct semantics for every point of the point cloud / vertex of the mesh in `data/scannet_gt_scenes/train` as `{scene}.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Data: ScanNet v2\n",
    "\n",
    "This demo is done for ScanNet, but other datasets will follow the same steps\n",
    "\n",
    "To evaluate the predicted results, we need to packproject them into the format of the given GT. This in combination with the visualization is done with the NERFSTUDIO Viewer. To bring the data into the format and compare it to the Baseline, we first run the baselines training script\n",
    "\n",
    "Make sure to run this cell in the opennerf environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "import files\n",
    "from eval.evaluator import Evaluator\n",
    "\n",
    "dataset = 'scannet'\n",
    "scene = 'scene0062_00'\n",
    "masks = 'ovseg'\n",
    "pairing = 'assignment'\n",
    "\n",
    "evaluator = Evaluator(dataset=dataset, scene=scene, masks=masks, pairing=pairing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.run_opennerf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we can run the function to evaluate the predicted semantics. For some reason this does not behave well in a Notebook Cell, even though it runns completely normal when called in scripts. We provide the way to call it in the pipeline as well as the execution in the shell (its the same command the method calls) to visualize how it will look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In your skript, just call it like this:\n",
    "#evaluator.eval_scene()\n",
    "\n",
    "#Note: Since for some reason this does not run in a notebook cell but otherwise works in the command line as it should, this cell is run as a shell command (same command the method calls)\n",
    "EXPERIMENT_NAME = 'benchmark'\n",
    "!{files.OPENNERF_ENV_PYTHON} {files.BASE_PATH}src/eval/{dataset}_semantics.py interpolate --interpolation-steps=1 --pose_source=train --load-config={files.OPENNERF_PATH}outputs/{dataset}_{scene}/opennerf/{EXPERIMENT_NAME}/config.yml --colormap-options.colormap=pca --output_path={files.OPENNERF_PATH}outputs/{dataset}_{scene}/opennerf/{EXPERIMENT_NAME}/ --rendered-output-names=rgb --eval-num-rays-per-chunk=500 --downscale-factor=1 --semantics_input_path={files.RESULT_PATH}semantic_labels/{pairing}_{scene}_{masks}.pickle --semantics_output_path={files.RESULT_PATH}pr_semantics/semantics_{pairing}_{scene}_{masks}.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to visualize the results, just follow the steps in the output above and the 3D Viewer in the Browser is activated\n",
    "\n",
    "After creating the corresponding `prediction.txt` file we can evaluate them with respect to the `gt.txt` files, and you see your predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.eval_semantics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opennerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
