{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Notebook: How to get data or delete them\n",
    "In this notebook, we will demonstrate how you can download and process scenes from common scene understanding datasets, s.t. they can be used for our method. For every scene, we need to make sure to have the following:\n",
    "- Scene data such as images, depth maps, intrinsics, and poses\n",
    "- A suitable ground-truth format to perform evaluation\n",
    "\n",
    "Additionally, we make sure to bring scenes and ground-truth into the Nerfstudio format to make use of their 3D visualizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data: Downloading and preprocessing Replica scenes\n",
    "\n",
    "To process a Replica Scene, the following steps are neccesary\n",
    "1. Download the Data, preprocessed by NICE-SLAM (https://pengsongyou.github.io/nice-slam)\n",
    "2. Transform it into nerfstudio format utilizing this script `data_processing/replica_preprocess.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "import files\n",
    "\n",
    "!{files.OPENNERF_ENV_PYTHON} {files.BASE_PATH}data_processing/replica/replica_preprocess.py --in_path PATH_TO_REPLICA_DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Data: Downloading and preprocessing ScanNet scenes\n",
    "Processing a ScanNet data consists of the following steps:\n",
    "1. Download the ScanNet data, incl. `.sens`-file for poses and camera parameters and `.ply`-files for the ground-truth 3D meshes\n",
    "2. Extract images, depth maps, intrinsics, and poses from `.sens`-files. Copy to the `data/nerfstudio`-folder for later visualization\n",
    "3. Run colmap preprocessing for sparse point cloud initalization of Gaussian Splatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scannet.scannet_processing as scannet_processing\n",
    "\n",
    "SCENE_NAME = \"scene0003_00\"\n",
    "DOWNSAMPLING_FACTOR = 3\n",
    "\n",
    "scannet_processing.preprocess_scene_data(SCENE_NAME, downsampling_factor=DOWNSAMPLING_FACTOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting files once you are done with a scene\n",
    "3D Semantic Segmentation has significant memory requirements for every scene. Once you are done with a whole scene, you may want to delete it. We provide a command to delete all raw data incl. all data that are created later on in the segmentation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scannet.scannet_processing as scannet_processing\n",
    "\n",
    "SCENE_NAME = \"scene0003_00\"\n",
    "\n",
    "scannet_processing.delete_scannet_data(SCENE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
